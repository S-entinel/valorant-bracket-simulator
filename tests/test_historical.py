import pytest
from historical_validation import HistoricalValidator


class TestHistoricalValidation:
    """Test validation against VCT Champions 2024."""

    def test_historical_teams_loaded(self):
        """Should load 8 VCT Champions 2024 teams."""
        validator = HistoricalValidator()
        teams = validator._get_historical_teams()
        
        assert len(teams) == 8
        assert teams[0]["name"] == "EDward Gaming"
        assert teams[0]["elo_rating"] == 1720.0

    def test_actual_results_loaded(self):
        """Should have actual tournament results."""
        validator = HistoricalValidator()
        results = validator._get_actual_results()
        
        assert results["champion"] == "EDward Gaming"
        assert results["runner_up"] == "Team Heretics"
        assert len(results["semifinals"]) == 2
        assert len(results["quarterfinals"]) == 4

    def test_create_validation_dataset(self, tmp_path):
        """Should create JSON file for validation."""
        validator = HistoricalValidator()
        
        # Monkey-patch the file creation to use tmp_path
        import historical_validation
        original_open = open
        
        def mock_open(filename, *args, **kwargs):
            if filename.endswith(".json"):
                filename = str(tmp_path / filename)
            return original_open(filename, *args, **kwargs)
        
        historical_validation.open = mock_open
        
        try:
            filename = validator.create_validation_dataset()
            assert (tmp_path / "vct_champions_2024_teams.json").exists()
        finally:
            historical_validation.open = original_open

    def test_validation_metrics_calculation(self):
        """Should calculate validation metrics correctly."""
        validator = HistoricalValidator()
        
        # Mock stats data
        stats = [
            {
                "name": "EDward Gaming",
                "championship_prob": 19.08,
                "finals_prob": 48.08,
            },
            {
                "name": "Team Heretics",
                "championship_prob": 16.64,
                "finals_prob": 42.98,
            },
            {
                "name": "LEVIATÃN",
                "championship_prob": 15.10,
                "finals_prob": 39.79,
            },
            {
                "name": "Sentinels",
                "championship_prob": 11.62,
                "finals_prob": 31.59,
            },
        ]
        
        metrics = validator._calculate_metrics(stats)
        
        assert metrics["champion_correct"] is True
        assert metrics["champion_prob"] == 19.08
        assert metrics["top4_overlap"] == 4  # All 4 predicted correctly

    def test_champion_prediction_correct(self):
        """EDward Gaming should be predicted as most likely winner."""
        validator = HistoricalValidator()
        
        # This will actually run simulations, so keep it small
        result = validator.run_validation(n_simulations=100)
        
        # EDG should be in top predictions
        predictions = result["predictions"]
        edg_stats = next(t for t in predictions if t["name"] == "EDward Gaming")
        
        # EDG should have high championship probability
        assert edg_stats["championship_prob"] > 0, "EDG should have non-zero win chance"